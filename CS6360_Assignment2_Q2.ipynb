{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) 1) 2)\n",
    "\n",
    "* Below are the functions to sample text from the model using different temperatures (i.e., 1/Î± values) and a function that uses an RNN to complete a string. Comments have been mentioned in the code itself.\n",
    "\n",
    "\n",
    "* For low values of alpha, the probability vector covers more of the given vocabulary and is more spread out. This ensures that each character has a high probability of being sampled.\n",
    "\n",
    "\n",
    "* For high values of alpha, the softmax function behaves like a max function. This ensures that the character with a higher probability gets picked. There would be repetition of the same word in the sentence.\n",
    "\n",
    "\n",
    "* The RNN generated text has been produced that is a plausible continuation of a given starter string. In order to do that, I have computed the hidden activity h at the end of the starter string, and then to start generating new text. Included 5 interesting examples of outputs that my network generated using a starter string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "data = open('shakespeare_train.txt', 'r').read()\n",
    "\n",
    "sequence_length = 1500\n",
    "hidden_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the trained weights \n",
    "a = numpy.load(open(\"char-rnn-snapshot.npz\"))\n",
    "Wxh = a[\"Wxh\"] \n",
    "Whh = a[\"Whh\"] \n",
    "Why = a[\"Why\"] \n",
    "bh = a[\"bh\"] \n",
    "by = a[\"by\"]\n",
    "chars = a[\"chars\"].tolist()\n",
    "data_size = a[\"data_size\"].tolist() \n",
    "vocab_size = a[\"vocab_size\"].tolist()\n",
    "char_to_ix = a[\"char_to_ix\"].tolist() \n",
    "ix_to_char = a[\"ix_to_char\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a sample text with an alpha value for temperature.\n",
    "def temp(length, alpha=1):\n",
    "\n",
    "  inputs = [char_to_ix[ch] for ch in data[:sequence_length]]\n",
    "  hs = numpy.zeros((hidden_size,1))\n",
    "  \n",
    "  # generates a sample\n",
    "  sample_ix = sample(hs, inputs[0], length, alpha)\n",
    "  txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "  print '_____\\n%s \\n_______' % (txt, )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample a sequence of integers from the model.\n",
    "def sample(h, seed_ix, n, alpha):\n",
    "\n",
    "  x = numpy.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ix_list = []\n",
    "  for t in xrange(n):\n",
    "    h = numpy.tanh(numpy.dot(Wxh, x) + numpy.dot(Whh, h) + bh)\n",
    "    y = numpy.dot(Why, h) + by\n",
    "    p = numpy.exp(alpha * y) / numpy.sum(numpy.exp(alpha * y))\n",
    "    ix = numpy.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = numpy.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ix_list.append(ix)\n",
    "  return ix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete a String\n",
    "def comp(m, n):\n",
    "\n",
    "  numpy.random.seed\n",
    "  begin_loc = numpy.random.randint(260000) \n",
    "  inputs = [char_to_ix[ch] for ch in data[begin_loc : begin_loc+sequence_length]]\n",
    "  h = numpy.zeros((hidden_size,1))\n",
    "  x = numpy.zeros((vocab_size, 1))\n",
    "  word_index = 0\n",
    "  ix = inputs[word_index]\n",
    "  x[ix] = 1\n",
    "\n",
    "  ix_list = []\n",
    "  ix_list.append(ix)\n",
    "  for t in xrange(m):\n",
    "    h = numpy.tanh(numpy.dot(Wxh, x) + numpy.dot(Whh, h) + bh)\n",
    "    x = numpy.zeros((vocab_size, 1))\n",
    "    ix = inputs[word_index + 1]\n",
    "    word_index += 1\n",
    "    x[ix] = 1\n",
    "    ix_list.append(ix)\n",
    "    # generates the context text\n",
    "  txt = ''.join(ix_to_char[ix] for ix in ix_list)\n",
    "  print 'Context text generated: \\n___________\\n %s \\n________ \\n' % (txt, )\n",
    "    # use the output as the next input where we start the continuation and compute the probability\n",
    "  y = numpy.dot(Why, h) + by\n",
    "  p = numpy.exp(y) / numpy.sum(numpy.exp(y))\n",
    "  ix = numpy.random.choice(range(vocab_size), p=p.ravel())\n",
    "  x = numpy.zeros((vocab_size, 1))\n",
    "  x[ix] = 1\n",
    "\n",
    "  # complete the string\n",
    "  ix_list = []\n",
    "  for t in xrange(n):\n",
    "    h = numpy.tanh(numpy.dot(Wxh, x) + numpy.dot(Whh, h) + bh)\n",
    "    y = numpy.dot(Why, h) + by\n",
    "    p = numpy.exp(y) / numpy.sum(numpy.exp(y))\n",
    "    ix = numpy.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = numpy.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ix_list.append(ix)\n",
    "  \n",
    "  # Generate the continuation\n",
    "  txt = ''.join(ix_to_char[ix] for ix in ix_list)\n",
    "  print 'Continuation text generated: \\n_________\\n %s \\n__________\\n' % (txt, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____\n",
      "irst Senath so the the the the the the the the the counter the the and the come the and the the the  \n",
      "_______\n"
     ]
    }
   ],
   "source": [
    "temp(100,alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____\n",
      "irst Cyely:\n",
      "I'l con'touve with arcould comand. Theike a were the to wit man.\n",
      "\n",
      "BRUTUS:\n",
      "It shingal lac \n",
      "_______\n"
     ]
    }
   ],
   "source": [
    "temp(100,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____\n",
      "ysW'Wbnrp,??\n",
      "!S-kNqYgC.m--wcU!hfni?nr-wEOZDd\n",
      "HPy,\n",
      "'xapjNIZAVKxy.UWBR;nPyEMpv'AKNiffs''V,EOQhAsomBui' \n",
      "_______\n"
     ]
    }
   ],
   "source": [
    "temp(100,alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text generated: \n",
      "___________\n",
      " o, you that banish'd him;\n",
      "A mile before his tent fall down, and knee\n",
      "The way into his mercy: nay, if  \n",
      "________ \n",
      "\n",
      "Continuation text generated: \n",
      "_________\n",
      " brepe thy mo, my bating no that,! for con you more be's not entary; for of bo?\n",
      "\n",
      "SICINIUS:\n",
      "Yim ok; onite with wise both she nervender comer.\n",
      "\n",
      "SICINI:\n",
      "Nad:\n",
      "surseet canp. Aghen in ed strotitwas. whet fel \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text generated: \n",
      "___________\n",
      " ius,\n",
      "That they of Rome are entered in our counsels\n",
      "And know how we proceed.\n",
      "\n",
      "AUFIDIUS:\n",
      "Is it not yours?\n",
      "What ever have been thought on in this state,\n",
      "That could be brought to bodily act ere Rome\n",
      "Had circumvention? 'Tis not four days gone\n",
      "Since I heard thence; these are the words: I think\n",
      "I have the l \n",
      "________ \n",
      "\n",
      "Continuation text generated: \n",
      "_________\n",
      " ou come, ant takes; unour. O in hest me Pounthest, 'Tis\n",
      "Let goss gromath de tay.\n",
      "\n",
      "VOLUMNIA:\n",
      "Seeltsthare?\n",
      "O netbyce\n",
      "To do trame as region him say knoth your of he stroine ny\n",
      "cuest\n",
      "\n",
      "VENBR:\n",
      "No in mitizen \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp(300,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text generated: \n",
      "___________\n",
      " y happy days before thy death;\n",
      "And, after many lengthen'd hours of grief,\n",
      "Die neither mother, wife, nor England's queen!\n",
      "Rivers and Dorset, you were standers by,\n",
      "And so wast thou, Lord Hastings, when my son\n",
      "Was stabb'd with bloody daggers: God, I pray him,\n",
      "That none of you may live your natural age,\n",
      "But by some unlook'd accident cut off!\n",
      "\n",
      "GLOUCESTER:\n",
      "Have done thy charm, thou hateful wither'd hag!\n",
      "\n",
      "QUEEN MARGARET:\n",
      "And leave out thee? stay, dog, for thou shalt hear me.\n",
      "If heaven have any grievous  \n",
      "________ \n",
      "\n",
      "Continuation text generated: \n",
      "_________\n",
      " \n",
      "\n",
      "First I'll love shall'd of noble wopts\n",
      "And had his art, he's pees, thou depo, I cond hearing gus thing hear gravered.! rot forlain a he'll\n",
      "sed beher?\n",
      "\n",
      "BRUTUS:\n",
      "Wheld your me what\n",
      "Rees-\n",
      "The of clam, good\n",
      "Whe will whigle onaing'd yes that the whanter voughery :\n",
      "Dly sil woul' he rewemeem this enem not?\n",
      "Of go to I'll as 'ttre oft go! my tere as all'lf,\n",
      "Me.\n",
      "\n",
      "CORIOLANUS:\n",
      "Con cuves than, me neich hance\n",
      "Thou son 'tar with that.\n",
      "Werm trilf coul the himse's, but it at intile,\n",
      "Wy him felly her, in keese hus flam.\n",
      "\n",
      "SICINIUS:\n",
      "Ho'd's he thim so gim of the she that the the gons stseecher ager:\n",
      "That wide dode? to uptore end not are the belseus as lose good, all bount be not dees shalo Auck, I lad: conuus o \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp(500,700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text generated: \n",
      "___________\n",
      " ws have made me stay, I fled from words.\n",
      "You soothed not, therefore hurt not: but\n",
      "your people,\n",
      "I love them as they weigh.\n",
      "\n",
      "MENENIUS:\n",
      "Pray now, sit down.\n",
      "\n",
      "CORIOLANUS:\n",
      "I had rather have one scratch my head i' the sun\n",
      "When the alarum were struck than idly sit\n",
      "To hear my nothings monster'd.\n",
      "\n",
      "MENENIUS:\n",
      "Masters of the people,\n",
      "Your multiplying spawn how can he flatter--\n",
      "That's thousand to one good one--when you now see\n",
      "He had rather venture all his limbs for honour\n",
      "Than one on's ears to hear it? Proceed, Cominius.\n",
      "\n",
      "COMINIUS:\n",
      "I shall lack voice: the deeds of Coriolanus\n",
      "Should not be utter'd feebly. It is held\n",
      "That valour is the chiefest virtue, and\n",
      "Most dignifies the haver: if it be,\n",
      "The man I speak  \n",
      "________ \n",
      "\n",
      "Continuation text generated: \n",
      "_________\n",
      " in the praity my pee's weind have while a no thou soldy:\n",
      "And that for you bood blind, the seromer:\n",
      "A \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp(700,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text generated: \n",
      "___________\n",
      " gs, then cursed she Buckingham,\n",
      "Then cursed she Richard. O, remember, God\n",
      "To hear her prayers for them, as now for us\n",
      "And for my sister and her princely sons,\n",
      "Be satisfied, dear God, with our true blood,\n",
      "Which, as thou know'st, unjustly must be spilt. \n",
      "________ \n",
      "\n",
      "Continuation text generated: \n",
      "_________\n",
      " be stwere hawny:\n",
      "I king word I kinouesatinst,\n",
      "And didy who as cowem!\n",
      "\n",
      "MENENIUS:\n",
      "I had mombe be that a caees pawnicl.\n",
      "\n",
      "VOLUMNIA:\n",
      "Whighter wot 'Tis, ind with; hid mee Halty:\n",
      "Nor is axanainst day; I mee,\n",
      "I'll finger lith groce:\n",
      "hear,\n",
      "A just fain thre our \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp(250,251)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) 3) 4)\n",
    "\n",
    "In the samples that the RNN generated, it seems that a newline or a space usually follows\n",
    "the colon (i.e., :) character.\n",
    "\n",
    "Wxh[100][9], Why[0][100] and Why[2][100] are the most responsible weights for\n",
    "causing this type of behaviour.\n",
    "\n",
    "When the character \":\" is passed in as the one-of-K encoding where the 9th\n",
    "entry in the input x is 1, the 9th column of Wxh gets picked up (Wxh[:, 9]).\n",
    "Also, the 100th entry of the hidden units h is the most\n",
    "activated with value of 0.9999, which is very large. Note that h being a tanh\n",
    "unit asymptotically approaches 1. This makes Whh and the previous hidden\n",
    "state insignificant. Wxh[100][9] is the most responsible for h[100] being very\n",
    "large.\n",
    "\n",
    "At the output stage, the hidden units is multiplied with the matrix Why.\n",
    "The result is that y[0] (newline character) and y[2] (space character) take on\n",
    "big values. This is because Why[0][100] and Why[2][100] are the\n",
    "biggest values in the Why[:, 100] column when the hidden units are activated at\n",
    "the 100th position.\n",
    "\n",
    "Large y[0] and y[2] make the newline character and space character very\n",
    "probable to be sampled after the softmax function turns the output vectors into\n",
    "a probability vector. That is why the newline and space character always follow the colon character."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
